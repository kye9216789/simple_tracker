{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "\n",
    "from mmdet import __version__\n",
    "from mmdet.datasets import get_dataset\n",
    "from mmdet.apis import (train_detector, init_dist, get_root_logger,\n",
    "                        set_random_seed)\n",
    "from mmcv.runner import load_checkpoint, parallel_test, obj_from_dict\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.datasets import build_dataloader\n",
    "from mmcv.parallel import scatter, collate, MMDataParallel\n",
    "from mmdet.core import bbox2roi, bbox2result, build_assigner, build_sampler\n",
    "from mmdet import datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "mmdet_dir = '/home/ye/github/mp_mmdetection/'\n",
    "work_dir = 'work_dirs/190604_retinanet_x101_32x4d_fpn_1x'\n",
    "sys.path.append(os.path.abspath(mmdet_dir))\n",
    "from mmdet.models import builder\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(1, -1)\n",
    "    \n",
    "\n",
    "class Tracker(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(Tracker, self).__init__()\n",
    "        self.cnn_module = TrackerCnnModule(cfg)\n",
    "        self.rnn_module = TrackerRnnModule(256*49, 500, 1).cuda() # TODO : save variable in config\n",
    "        \n",
    "    def forward(self, img, img_meta):\n",
    "        bbox_feats = self.cnn_module(img, img_meta)\n",
    "        pred = self.rnn_module(bbox_feats)\n",
    "        return pred\n",
    "\n",
    "\n",
    "class TrackerRnnModule(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "                    num_layers=2):\n",
    "        super(TrackerRnnModule, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return pred.view(-1)\n",
    "    \n",
    "\n",
    "class TrackerCnnModule(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(TrackerCnnModule, self).__init__()\n",
    "        model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "        checkpoint = glob.glob(os.path.join(mmdet_dir, work_dir, '*.pth'))[0]\n",
    "        load_checkpoint(model, checkpoint)\n",
    "        model = MMDataParallel(model, device_ids=[0])\n",
    "\n",
    "        self.bbox_roi_extractor = builder.build_roi_extractor(cfg.bbox_roi_extractor)\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.detector = model.module\n",
    "        self.flatten = Flatten()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "    def forward(self, img, img_meta, rescale=False):\n",
    "        x = self.detector.extract_feat(img)\n",
    "        outs = self.detector.bbox_head(x)\n",
    "        bbox_inputs = outs + (img_meta, cfg.test_cfg, rescale)\n",
    "        bboxes, cls = self.detector.bbox_head.get_bboxes(*bbox_inputs)[0]\n",
    "        rois = bbox2roi([bboxes])\n",
    "        bbox_feats = self.bbox_roi_extractor(x[:self.bbox_roi_extractor.num_inputs], rois)[0]\n",
    "        bbox_feats = self.flatten(bbox_feats)\n",
    "        return bbox_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.47s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "missing keys in source state_dict: layer3.5.bn2.num_batches_tracked, layer3.8.bn1.num_batches_tracked, layer2.1.bn1.num_batches_tracked, layer3.8.bn3.num_batches_tracked, layer3.20.bn1.num_batches_tracked, layer3.19.bn2.num_batches_tracked, layer3.7.bn1.num_batches_tracked, layer3.2.bn2.num_batches_tracked, layer3.19.bn3.num_batches_tracked, layer3.0.downsample.1.num_batches_tracked, layer3.10.bn3.num_batches_tracked, layer1.2.bn2.num_batches_tracked, layer2.3.bn2.num_batches_tracked, layer3.17.bn3.num_batches_tracked, layer3.14.bn1.num_batches_tracked, layer3.0.bn1.num_batches_tracked, layer3.6.bn1.num_batches_tracked, layer2.2.bn1.num_batches_tracked, layer1.0.bn2.num_batches_tracked, layer2.1.bn2.num_batches_tracked, layer2.2.bn3.num_batches_tracked, layer3.6.bn2.num_batches_tracked, layer1.2.bn3.num_batches_tracked, layer3.1.bn3.num_batches_tracked, layer3.9.bn3.num_batches_tracked, layer3.16.bn1.num_batches_tracked, layer3.4.bn1.num_batches_tracked, layer3.16.bn3.num_batches_tracked, layer3.2.bn1.num_batches_tracked, layer3.3.bn1.num_batches_tracked, layer3.11.bn3.num_batches_tracked, layer3.13.bn1.num_batches_tracked, layer3.0.bn3.num_batches_tracked, layer3.4.bn2.num_batches_tracked, layer1.1.bn2.num_batches_tracked, layer3.13.bn3.num_batches_tracked, layer2.0.bn2.num_batches_tracked, layer3.3.bn3.num_batches_tracked, layer3.15.bn3.num_batches_tracked, layer3.6.bn3.num_batches_tracked, layer3.1.bn2.num_batches_tracked, layer3.15.bn2.num_batches_tracked, layer3.22.bn2.num_batches_tracked, layer3.11.bn1.num_batches_tracked, layer1.0.bn1.num_batches_tracked, layer2.3.bn1.num_batches_tracked, layer3.0.bn2.num_batches_tracked, layer3.18.bn2.num_batches_tracked, layer3.22.bn1.num_batches_tracked, layer3.16.bn2.num_batches_tracked, layer1.1.bn3.num_batches_tracked, layer2.1.bn3.num_batches_tracked, layer3.12.bn2.num_batches_tracked, layer3.5.bn1.num_batches_tracked, layer1.0.downsample.1.num_batches_tracked, layer3.20.bn2.num_batches_tracked, layer3.15.bn1.num_batches_tracked, layer3.2.bn3.num_batches_tracked, layer2.0.bn3.num_batches_tracked, layer4.1.bn2.num_batches_tracked, layer3.17.bn2.num_batches_tracked, layer3.19.bn1.num_batches_tracked, layer3.21.bn3.num_batches_tracked, layer2.2.bn2.num_batches_tracked, layer3.3.bn2.num_batches_tracked, layer4.0.bn1.num_batches_tracked, layer4.2.bn1.num_batches_tracked, layer3.4.bn3.num_batches_tracked, layer2.3.bn3.num_batches_tracked, layer3.18.bn1.num_batches_tracked, layer3.9.bn1.num_batches_tracked, layer3.9.bn2.num_batches_tracked, layer3.7.bn2.num_batches_tracked, layer1.1.bn1.num_batches_tracked, layer3.13.bn2.num_batches_tracked, layer4.0.downsample.1.num_batches_tracked, layer4.2.bn2.num_batches_tracked, layer3.14.bn3.num_batches_tracked, layer4.2.bn3.num_batches_tracked, layer2.0.bn1.num_batches_tracked, layer4.0.bn2.num_batches_tracked, layer3.14.bn2.num_batches_tracked, layer3.8.bn2.num_batches_tracked, layer3.21.bn1.num_batches_tracked, layer2.0.downsample.1.num_batches_tracked, layer3.12.bn3.num_batches_tracked, layer4.1.bn3.num_batches_tracked, layer3.10.bn1.num_batches_tracked, layer3.7.bn3.num_batches_tracked, layer3.10.bn2.num_batches_tracked, layer3.17.bn1.num_batches_tracked, layer3.20.bn3.num_batches_tracked, layer1.2.bn1.num_batches_tracked, layer1.0.bn3.num_batches_tracked, layer3.18.bn3.num_batches_tracked, layer3.22.bn3.num_batches_tracked, layer3.11.bn2.num_batches_tracked, layer3.5.bn3.num_batches_tracked, layer4.1.bn1.num_batches_tracked, layer4.0.bn3.num_batches_tracked, layer3.1.bn1.num_batches_tracked, layer3.21.bn2.num_batches_tracked, bn1.num_batches_tracked, layer3.12.bn1.num_batches_tracked\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(glob.glob(os.path.join(mmdet_dir, work_dir, '*.py'))[0])\n",
    "cfg.work_dir = work_dir\n",
    "cfg.mmdet_dir = mmdet_dir\n",
    "\n",
    "dataset = obj_from_dict(cfg.data.train, datasets, dict(test_mode=False))    \n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    imgs_per_gpu=1,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    num_gpus=1,\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "\n",
    "tracker = Tracker(cfg)\n",
    "dataset = data_loader.dataset\n",
    "for i, data in enumerate(data_loader):\n",
    "    img_meta = data['img_meta'].data[0]\n",
    "    img = data['img'].data[0].cuda()\n",
    "    pred = tracker(img, img_meta)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo : train / inference 정의"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python mm",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
